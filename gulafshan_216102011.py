# -*- coding: utf-8 -*-
"""Gulafshan_216102011.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TZ5C9XNYkuuWtCWOFvI9zAjaftmtEcLv

Pedestrian detection and segmentation from video using computer vision techniques
"""

#mounting derive
from google.colab import drive
drive.mount('/content/drive')

#importing all required libraries
import cv2
from google.colab.patches import cv2_imshow
import numpy as np

def detection(frame1,frame2):

    #absolute difference is used to compare two frames,current frame with previous one.
    abs_diff = cv2.absdiff(frame1, frame2)

    # Conversion from rgb to gray level,grey = 0.30*R + 0.59*G + 0.11*B
    gray_image = cv2.cvtColor(abs_diff, cv2.COLOR_BGR2GRAY)

     # applying Gaussian Blurring on grey image,5*5 is kernel size, Intent to reduce the noise in the image 
    blurred_image = cv2.GaussianBlur(gray_image, (5,5), 0)

    #Calculating Threshold ,a threshold is applied so that we get a nice shapes of moving object in black
    #if pixel value is T>20 then assigned to 255 is white otherwise as black,we get thresh as threshold image
    _, thresh = cv2.threshold(blurred_image, 20, 255, cv2.THRESH_BINARY)

    #dialation of image is used to make features of image prominent
    dilated_image = cv2.dilate(thresh, None, iterations=3)

    """Finding contours of dilated image , contour retrieval mode and contour approximation method used
    Each individual contour is a Numpy array of (x,y) coordinates of boundary points of the object.
    It Returns the detected contours as a list of points and the contour hierarchy"""
    contours, _ = cv2.findContours(dilated_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

    
    for i in contours:
        (x, y, w, h) = cv2.boundingRect(i) # (x,y) be the top-left coordinate of the rectangle and (w,h) be its width and height.

        if cv2.contourArea(i) < 900:
                continue
        cv2.rectangle(frame1, (x, y), (x+w, y+h), (0, 255, 0), 2)
        cv2.putText(frame1, "Pedestrian Detection", (10, 20), cv2.FONT_HERSHEY_SIMPLEX,1, (0, 0, 255), 3)
    return frame1

#for segmentation of image
def segmentation(frame2,fgbg_image):
    kernel = np.ones((4,4),np.uint8) # 4*4 ones kernel matrix
    seg_image = np.zeros(frame2.shape, np.uint8) # array of shape frame2 filled with 0

    fgmask = fgbg_image.apply(frame2)# applying subtractor on each frame2
    fgmask = cv2.morphologyEx(fgmask , cv2.MORPH_OPEN, kernel) #OPEN and then CLOSE to get more smooth shapes
    seg_image[:,:,0] = fgmask #Blue channel
    seg_image[:,:,1] = fgmask #Green channel
    seg_image[:,:,2] = fgmask #Red channel
    result = cv2.bitwise_and(frame2, frame2, mask=fgmask)
    cv2.putText(seg_image, "Pedestrian Segmentation", (10, 20), cv2.FONT_HERSHEY_SIMPLEX,1, (0, 0, 255), 3)
    cv2.putText(result, "Background Reduction", (10, 20), cv2.FONT_HERSHEY_SIMPLEX,1, (0, 0, 255), 3)
    return seg_image,result

#pedestrian detection
def Pedestrian_detection(cap,out):

    #subtracting the background using algorithm BackgroundSubtractorMOG2 
    fgbg_image = cv2.createBackgroundSubtractorMOG2()

    #starting reading of the frames
    while cap.isOpened():
        #explanation of cap read
        #ret: This is a boolean value that is true if the frame is read successfully, else false
        #frame1:  This is the actual frame that is read.
        #This frame can be stored in a variable and can be used similar to how we loaded individual images using cv2.imread()
        ret, frame1 = cap.read()
        ret, frame2 = cap.read()

        #if the frame is successfully read doing segmentation, detection on the frame
        if ret==True:
            seg,res = segmentation(frame2,fgbg_image)
            frame1 = detection(frame1,frame2)
            frame_org=frame2.copy()
            cv2.putText(frame_org, "Video streem", (10, 20), cv2.FONT_HERSHEY_SIMPLEX,1, (0, 0, 255), 3)
            image_list1=[frame_org,frame1]
            image_list2=[seg,res]
            img1=np.hstack(image_list1)
            img2=np.hstack(image_list2)
            image_list=[img1,img2]
            img_f=np.vstack(image_list)
            img_f1 = cv2.resize(img_f, (int(img_f.shape[1]//1.5),int(img_f.shape[0]//1.5)))

            cv2_imshow(img_f1)
            out.write(img_f)
            if cv2.waitKey(40) == 27:
                break
        else:
            break

    cv2.destroyAllWindows() #destroy the window showing images
    cap.release() # release the resources
    out.release()

if __name__=="__main__":
    cap = cv2.VideoCapture('/content/drive/My Drive/Gulafhsan_project/input_video/vtest.avi')

    #getting the width of the frame of the video
    frame_width = int( cap.get(cv2.CAP_PROP_FRAME_WIDTH))

    #getting the height of the frame of the video
    frame_height =int( cap.get( cv2.CAP_PROP_FRAME_HEIGHT))

    #Encoding avi video works by setting the FOURCC code to ‘XVID’ 
    #fourcc code is the sequence of bytes identify the data formats
    fourcc = cv2.VideoWriter_fourcc('X','V','I','D')
    out = cv2.VideoWriter("/content/drive/My Drive/new_output.mp4", fourcc, 5.0, (int((frame_width*2)),int((frame_height*2))))
    Pedestrian_detection(cap,out)